\begin{dfn}
    Let $K$ be a functor from commutative rings to groups.
    Recall from~\cite{LSV2} that $K$ is called \textit{locally acyclic (resp., locally acyclic for domains)} if for every commutative local ring (resp., domain)
     $A$ the following diagram whose arrows are induced by natural embeddings is a pullback square:
    \begin{equation}\label{eq:P1-square} \begin{tikzcd} K(A) \ar[r] \ar[d] & K(A[X]) \arrow{d} \\ K(A[X\inv]) \ar{r} & K(A[X, X\inv]). \end{tikzcd} \end{equation}
\end{dfn}

Now we can formulate the main result of this section.
\begin{thm}[Horrocks theorem for $\K_2$]\label{thm:horrocks-k2}
Let $\Phi$ be a root system of type $\rA_{\geq 4}$, $\rD_{\geq 5}$, $\rE_6$ or $\rE_7$.
Then the functor $\K_{2}(\Phi, -)$ is locally acyclic for domains.
\end{thm}
Horrocks theorem for $\K_2$ has been previously known in the linear and even orthogonal case $\Phi=\rA_{\geq 4},\rD_{\geq 7}$, see~\cite[Proposition~4.3]{Tu83} and~\cite[Theorem~1]{LS20}, respectively.
Notice that the orthogonal Horrocks theorem for $\K_2$ \cite[Theorem~1]{LS20} was proved only under the additional assumption $2 \in A^\times$.
Thus, the novelty of~\cref{thm:horrocks-k2} consists not only in the fact that it applies to root systems of types $\rD_5$, $\rD_6$, $\rE_6$, $\rE_7$ but also that
 it is proved without the assumption $2 \in A^\times$.

Since our proof of \cref{thm:horrocks-k2} is rather long and technical we will first try to describe its plan.

Let $A$ be a local ring with maximal ideal $M$ and residue field $k$.
Recall that proofs of the Horrocks theorem for $\K_1$ are usually based on the decomposition of the elementary subgroup over Laurent polynomial ring
 called \textit{Suslin's lemma} or \textit{Suslin's structure theorem}, cf.~\cite{Abe83, Su77}, \cite[\S~VI.6]{Lam10}.
In the linear case this decomposition asserts that the elementary linear group $\E(n, A[X, X\inv]) = \Esc(\rA_{n-1}, A[X, X\inv])$ admits the following group factorization for $n \geq 3$:
\begin{equation}\label{eq:triple-decomposition}
\E(n, A[X^{\pm 1}]) = \E(n, A[X]) \cdot B(A[X^{\pm 1}]) \cdot \E(n, A[X^{\pm 1}], M[X^{\pm 1}]).
\end{equation}
In the above formula $\E(n, R, I)$ denotes the relative elementary subgroup, i.\,e. the kernel of the canonical reduction homomorphism $\E(n, R) \to \E(n, R/I),$
 while $B(R)$ denotes the Borel subgroup (i.\,e. the semidirect product of the unipotent radical $\UU(\Phi^+, R)$ and the group of diagonal matrices).

To prove the Suslin's structure theorem one constructs a collection of diagonal automorphisms $\delta_i$, $1\leq i\leq n$
 and shows that the product $V$ of the three subgroups in the right-hand side of~\eqref{eq:triple-decomposition} is stabilized by these automorphisms.
On the other hand, the product $V$ is clearly stabilized by left translations by elements of $\E(n, A[X])$.
Since the minimal subgroup of $\E(n, A[X, X\inv])$ that contains the image of $\E(n, A[X])$ and at the same time is invariant with respect to the conjugation by all $\delta_i$
  coincides with all of $\E(n, A[X, X\inv])$, the decomposition~\eqref{eq:triple-decomposition} follows.

Tulenbaev's proof of the Horrocks theorem for $\K_2$ is similar to Suslin's proof of the Horrocks theorem for $\K_1$.
The main difference, however, is that simply proving an factorization of the form~\eqref{eq:triple-decomposition} for the Steinberg group $\St(\Phi, A[X, X\inv])$
 would not be sufficient.
Instead, one has to prove a much more precise result, namely one has to construct a ``model set'' $V$ for the group $\St(\Phi, A[X, X\inv])$
 out of the same three ingredient groups: $\St(\Phi, A[X])$, Borel subgroup and the relative group $\St(\Phi, A[X^\pm], M[X^\pm])$.
By a ``model set'' we mean a set upon which $\St(\Phi, A[X, X\inv])$ would act simply-transitively.
This technique probably dates back to~\cite{ST76}, where it was used to prove the injective stability theorem for $\K_2$, it was also reused
 by M.~Tulenbaev in his proof of the Horrocks theorem for $\K_2$ in the linear case, cf.\ Propositions 4.1 and 4.3 in~\cite{Tu83}.
The same technique is also used in the proof of~\cite[Theorem~3]{LS20}, which is a direct generalization of~\cite[Proposition~4.3]{Tu83}.
We will use the same technique for the proof of~\cref{thm:horrocks-k2}, which, by analogy, should be thought of as a generalization of~\cite[Proposition~4.1]{Tu83}.

Now let us list the key steps of the proof:
\begin{itemize}
    \item Step 1. First of all, in~\cref{subsec:triples} we introduce abstract formalism of group decompositions which will allow us to construct the set $V$ modeling the Steinberg group $\St(\Phi, A[X, X\inv])$.
                  This should be thought of as preparatory work needed for the formulation of the $\K_2$-analogue of Suslin's structure theorem~\eqref{eq:triple-decomposition}.
    \item Step 2. In~\cref{subsec:structure-theorem-overview} we use this formalism to construct the "model set" $V$ and, thus, formulate the $\K_2$-analogue of Suslin's structure theorem precisely.
                  We also show how~\cref{thm:horrocks-k2} can be reduced to a concrete technical statement, namely,
                  to the existence of the action of $\St(\Phi, A[X, X\inv])$ on $V$.
\end{itemize}
Obviously, \cref{prop:rel-poly-Laurent} reduces the problem of construction of the action of $\St(\Phi, A[X, X\inv])$ on $V$ to the construction of
 the automorphism $\sigma_k$ of $V$ modeling the action of the weight automorphism $\chi_{\varpi_k, X}$ (cf.~\cref{subsec:weight-automorphisms}).
Here index $k$ has the same meaning as in Fig.~1 of~\cref{sec:affine}, namely it is the index of the simple root marked green on the extended Dynkin diagram.
The construction of $\sigma_k$ proceeds as follows:
\begin{itemize}
    \item Step 3. First, we have to show the existence of $\varpi_k^\vee$-pair in the sense of~\cref{dfn:delta-pair}.
                  Firstly, we construct $\varpi_1^\vee$-pair for the root system of type $\rA_3$ using the presentation from~\cref{prop:rel-presentation} for this purpose.
                  Next, we use the amalgamation theorem~\cref{thm:relPres} to obtain the general result.
                  This is achieved in~\cref{subsec:construction-sigma}.
    \item Step 4. Finally, we complete the construction of the action of $\St(\Phi, A[X, X\inv])$ on $V$ and verify all the neccessary relations.
                  This is achieved in~\cref{sec:construction-delta}.
\end{itemize}

\subsection{Formalism of triples}\label{subsec:triples}
Let $N$ be a group acting on itself by right conjugation.
Let $M$ be a group with a right action of $N$.
Recall that a group homomorphism $\mu\colon M \to N$ is called a \textit{precrossed module} if $\mu$ preserves the action of $N$, i.\,e.
\[\mu(m^n) = \mu(m)^n, \text{for all $m \in M$, $n\in N;$} \]
If, in addition, $\mu$ satisfies the so-called \textit{Peiffer identity}, i.\,e.
\[{m}^{\mu(m')} = {m'}^{-1} m m', \text{for all $m, m' \in M$,}\]
then $\mu$ is called a \textit{crossed module}.

If $\mu\colon M \to N$ and $\mu' \colon M' \to N'$ is a pair of precrossed modules.
A \textit{map of precrossed modules} $(f, g)\colon \mu \to \mu'$ is a pair of group homomorphisms $f\colon M \to M'$, $g\colon N \to N'$ such that
$\mu'f = g \mu$ and that the action of $N$ is preserved, i.\,e. ${f(m)}^{g(n)} = f(m^n)$ for all $n \in N$, $m \in M$.

Now suppose that we are given the following cube-like commutative diagram of abstract groups:
\begin{equation} \label{eq:cube} \begin{split} \xymatrix{
    G_{123} \ar[rr]_{f_{23}} \ar[dd]_{f_{12}} \ar[rd]_{f_{13}} &                        & G_{23} \ar@{-->}[dd]^(.3){g_2^3} \ar[rd]^{g^2_3} &           \\
    & G_{13} \ar[rr]^(.3){g^1_3} \ar^(.3){g^3_1}[dd] &                   & G_3 \ar[dd]_{h_3} \\
    G_{12} \ar@{-->}[rr]^(.3){g_2^1} \ar[rd]_{g_1^2}          &                        & G_2 \ar@{-->}[rd]_{h_2}         &           \\
    & G_1 \ar[rr]_{h_1}              &                   & G.} \end{split} \end{equation}
Additionally, we make the following assumptions:
\begin{itemize}
    \item $g_1^3$ is a precrossed module;
    \item $h_3$ is a crossed module;
    \item $(g_3^1, h_1) \colon g_1^3 \to h_3$ is a map of precrossed modules.
\end{itemize}
Set $V = G_1 \times G_2 \times G_3$, $W = G_{12} \times G_{13} \times G_{23}$.
We define an operation $\star \colon W \times V \to V$ as follows.
For $v = (x, y, z) \in V$ and $w = (a, b, c) \in W$ we set
\[(a, b, c) \star (x, y, z) = (x \cdot g_1^3(b) \cdot g_1^2(a),\ g_2^1(a)^{-1} \cdot y \cdot g_2^3(c),\ g_3^2(c)^{-1} \cdot g_3^1(b)^{-h_2(y)} \cdot z).\]
Consider the set-theoretic map $h \colon V \to G$ given by $(x, y, z) \mapsto h_1(x) \cdot h_2(y) \cdot h_3(z)$.
It is clear from the definition of $\star$-operation that for $w \in W$ one has $h(w \star v) = h(v).$
Now let us define the relation associated with $\star$-operation.
We declare two elements $v, v' \in V$ congruent (denoted $v \sim_W v'$) if $v' = w \star v$ for some triple $w=(a, b, c) \in W$.
As the following lemma shows, this relation is an equivalence relation.
\begin{lemma} For every $v \in V$ one has
\begin{equation*}(a', b', c') \star \left( (a, b, c) \star v \right) = (a \cdot a', b \cdot {b'}^{g_1^2(a)^{-1}}, c \cdot c') \star v.\end{equation*}
\end{lemma}
\begin{proof}
    Set $v'=(x', y', z') = (a, b, c) \star v$ and $(x'', y'', z'') = (a', b', c') \star v'$.
    Since $g_1^3$ is a precrossed module we immediately obtain that
    \begin{align*}
        x'' =& x' \cdot g_1^3(b') \cdot g_1^2(a') = x \cdot g_1^3(b) \cdot g_1^2(a) \cdot g_1^3(b') \cdot g_1^2(a') = x \cdot g_1^3(b \cdot b'^{g_1^2(a)^{-1}}) g_1^2(a \cdot a'),\\
        y'' =& g_2^1(a')^{-1} \cdot g_2^1(a)^{-1} \cdot y \cdot g_2^3(c) \cdot g_2^3(c') = g_2^1(a\cdot a')^{-1} \cdot y \cdot g_2^{3}(c\cdot c'). \end{align*}
    Since $(g_3^1, h_1)$ is a map of precrossed modules, for every $a \in G_{12}$, $b \in G_{13}$ one has $g_3^1(b^{g_1^2(a)}) = g_3^1(b)^{h_1 g_1^2(a)} = g_3^1(b)^{h_2g_2^1(a)}$.
    Since $h_3$ satisfies Peiffer identity, for every $c \in G_{23}$ and $z \in G_3$ one has $z ^{h_2 g_2^3(c)} = z^{ h_3 g_3^2(c)} = g_3^2(c)^{-1} \cdot z \cdot g_3^2(c)$.
    Using these identities we obtain that
    \begin{multline*}
        z'' = g_3^2(c')^{-1} \cdot g_3^1(b')^{-h_2(y')} \cdot z' = \\
        = g_3^2(c')^{-1} \cdot g_3^1(b')^{- h_2 \left( g_2^1(a)^{-1} \cdot y \cdot g_2^3(c) \right)} g_3^2(c)^{-1} \cdot g_3^1(b)^{-h_2(y)} \cdot z = \\
        = g_3^2(c \cdot c')^{-1} \cdot g_3^1(b')^{- h_2 \left( g_2^1(a)^{-1} \cdot y \right)} \cdot g_3^1(b)^{-h_2(y)} \cdot z = \\
        = g_3^2(c \cdot c')^{-1} \cdot g_3^1(b \cdot {b'} ^ {g_1^2(a)^{-1}})^{- h_2 \left( y \right)} \cdot z. \qedhere
    \end{multline*}
\end{proof}
Since $h$ is constant on the orbits of $\star$-action, $h$ gives rise to a well-defined map $\overline{h} \colon V/\sim_W \to G$.
We use the notation $[a, b, c]$ to denote the equivalence class of the triple $(a, b, c) \in V$.

\begin{lemma}\label{lem:one-one-z} Assume that the back face $(f_{12}, f_{23}, g_2^1, g_2^3)$ of~\eqref{eq:cube} is a pullback square.
Assume additionally that $[1, 1, 1] = [1, 1, z]$ for some $z\in G_3$.
Then $z \in g_3^1(\Ker(g_1^3)).$ \end{lemma}
\begin{proof} By the definition of congruence relation there exists $(a, b, c)\in W$ such that
\[ (a, b, c) \star (1, 1, 1) = ( g_1^3(b) \cdot g_1^2(a),\ g_2^1(a)^{-1} \cdot g_2^3(c),\ g_3^2(c)^{-1} \cdot g_3^1(b)^{-1}) = (1,1,z). \]
By lemma's assumption there exists $e \in G_{123}$ such that $f_{12}(e) = a$, $f_{23}(e) = c$, hence
\[ 1 = g_1^3(b) \cdot g_1^2(f_{12}(e)) = g_1^3(b \cdot f_{13}(e)),\ z = g_3^2(f_{23}(e))^{-1} \cdot g_3^1(b)^{-1} = g_3^1(b \cdot f_{13}(e))^{-1}. \qedhere\] \end{proof}


\subsection{First reductions} \label{subsec:structure-theorem-overview}
%sSignificant progress towards proving~\cref{thm:horrocks-k2} has already been achieved in~\cite{LS20}.
%In this subsection we reduce~\cref{thm:horrocks-k2} to a specific technical statement which will be addressed in the following sections.

The following lemma provides the first key reduction in the proof of~\cref{thm:horrocks-k2}.
\begin{lemma} \label{lem:first-reduction}
Let $A$ be a local ring with maximal ideal $M$ and residue field $k$.
Let $\Phi$ be as in the statement of~\cref{thm:horrocks-k2}.
Suppose that the canonical homomorphism
\begin{equation} \label{eq:c-surj} C(\Phi, A[X], M[X]) \to C(\Phi, A[X, X\inv], M[X, X\inv]) \end{equation}
is surjective.
Then the square~\eqref{eq:P1-square} is pullback and Horrocks theorem for $\K_2$ holds.
\end{lemma}
\begin{proof}
    Denote by $R$ the Laurent polynomial ring $A[X, X\inv]$ and by $B$ the subring $A[X\inv] + M[X] \subseteq R$.
    We also set $I \subseteq M[X, X\inv]$, which is clearly an ideal of both $B$ and $R$.
    Consider the following diagram with rows obtained from~\eqref{eq:relative-Steinberg}:
    \[\begin{tikzcd}
          C(\Phi, B, I) \arrow{r} \arrow[d, swap, twoheadrightarrow] & \St(\Phi, B, I) \arrow{r}{\mu_B} \arrow{d} & \St(\Phi, B) \arrow{r} \arrow{d} & \St(\Phi, k[X^{-1}]) \arrow[hookrightarrow]{d} \\
          C(\Phi, R, I) \arrow{r} & \St(\Phi, R, I) \arrow{r}{\mu_R} \arrow[ur, "t", dashrightarrow] & \St(\Phi, R) \arrow{r} & \St(\Phi, k[X, X^{-1}]).
    \end{tikzcd}\]
    The lifting $t$ is obtained from~\cite[Lemma~3.3]{LS20}.
    The right-hand side vertical arrow is injective by~\cite[Lemma~2.2]{LS20}.
    The left-hand side vertical arrow is surjective since the composite arrow
    $\xymatrix{ C(\Phi, A[X], M[X]) \ar[r] & C(\Phi, B, I) \ar[r] & C(\Phi, R, I) }$
    is surjective by lemma's assumption.
    It remains to repeat the diagram chasing argument of~\cite[Theorem~1]{LS20} to conclude that the homomorphism $\St(\Phi, B) \to \St(\Phi, A[X, X\inv])$ is injective.
    The assertion of the lemma will then follow from~\cite[Theorem~3]{LS20}.
\end{proof}
The proof of Horrocks theorem is, thus, reduced to showing that~\eqref{eq:c-surj} is surjective for every local domain $(A, M)$.
In fact, we will prove a stronger assertion.
In order to formulate the second reduction we need to recollect some notation pertaining to subgroups of $\St(\Phi, R)$.

%Not let us introduce shorter notation for Steinberg groups and their subgroups relevant for the proof of Horrocks theorem.
\begin{align*}
    G     =& \St(\Phi, A[X, X^{-1}]),\\
    G^+   =& \St(\Phi, A[X]),\\
    B     =& \UU(\Phi^+, A[X, X\inv]) \rtimes \StH(\Phi, A[X, X\inv]) \leq G,\\
    G_M   =& \St(\Phi, A[X, X^{-1}], M[X, X^{-1}]),\\
    U^+   =& \UU(\Phi^+, A[X]),\\
    G^+_M =& \St(\Phi, A[X], M[X]),\\
    B_M   =& \UU(\Phi^+, M[X, X^{-1}]) \times \{X, 1+M\} \leq G_M,\\
    U^+_M =& \UU(\Phi^+, M[X]).
\end{align*}
In the definition of $B_M$ we denote by $\{X, 1+M\}$ the image of the homomorphism $\{X, -\}_{r}$ from~\eqref{eq:relative-symbol}.

The above groups can be organized into the following commutative diagram:
\begin{equation} \label{eq:cube-Steinberg} \xymatrix{
    U^+_M \ar@{^{(}->}[rr] \ar@{^{(}->}[dd] \ar@{^{(}->}[rd] &                        & B_M \ar[dd]^(.3){g_B^M} \ar@{^{(}->}[rd]^{g^B_M} &           \\
    & G^+_M \ar[rr]^(.3){g^+_M} \ar^(.3){g^M_+}[dd] &                   & G_M \ar[dd]_{h_M} \\
    U^+ \ar@{^{(}->}[rr]^(.3){g_B^+} \ar@{^{(}->}[rd]_{g_+^B}          &                        & B \ar@{^{(}->}[rd]_{h_B}       &           \\
    & G^+ \ar[rr]_{h_+}              &                   & G.}\end{equation}
Here $g^M_+$ and $h_M$ are just renamed homomorphisms $\mu$ from~\eqref{eq:relative-Steinberg}.
Homomorphism $g^M_B$ is also induced by $\mu$.
Maps $g_M^+$ and $h^+$ are induced by the ring embedding $A[X] \to A[X, X\inv]$.
The other homomorphisms on the diagram are all obvious subgroup embeddings.

Set $V = G^+\times B \times G_M$, $W = U^+\times G^+_M \times B_M$.
Both homomorphisms $g_+^M$ and $h_M$ are crossed modules by~\cref{lem:rel-Steinberg-crossed-module}.
The fact that $(g^+_M, h_+)$ is a map of precrossed modules is obvious.
Thus, we find ourselves in the situation of~\cref{subsec:triples}.

The following lemma provides the second key reduction in the proof of Horrocks theorem.
\begin{lemma}
    Suppose that $A$ is a domain.
    Suppose that $V/\sim_W$ admits an action of $G$ such that
      for $g \in G_M$ one has \[ h_M(g) \cdot [1, 1, 1] = [1, 1, g]. \]
    Then the canonical homomorphism~\eqref{eq:c-surj} is surjective.
\end{lemma}
\begin{proof}
  Since $A$ is a domain, $g^M_B$ is injective by~\cref{lem:symbols}.
    Thus, the back face of~\eqref{eq:cube-Steinberg} is pull-back.
  Notice that for any $g \in C(\Phi, A[X, X\inv], M[X, X\inv]) \subseteq G_M$ one has
    \[ [1, 1, 1] = h_M(g) \cdot [1, 1, 1] = [1, 1, g].\]
  It is clear now that $g$ lies in the image of $C(\Phi, A[X], M[X])$ under $g^+_M$ by~\cref{lem:one-one-z}.
\end{proof}

\begin{rem}
    Notice that in the linear case the symbol homomorphism $A^\times \to \K_2(A[X, X\inv])$, $a \mapsto \{a, X\}$ admits section
     for a general commutative ring $A$ by~\cite{Wa71}.
    Thus, in the linear case the assertion of the lemma remains true without the assumption that $A$ is a domain, cf.~\cite[Lemma~3.1g]{Tu83}.
\end{rem}

\subsection{Construction of the homomorphism $\sigma(\varpi_k^\vee$)} \label{subsec:construction-sigma}
\input{pairconstr}

\subsection{Construction of the action of $\St(\Phi, A[X, X\inv])$ on $V$} \label{sec:construction-delta}
Recall that \[V = G^+ \times B \times G_M,\ W = U^+ \times G_M^+ \times B_M\]
and that $W$ acts upon $V$ via $\star$.
Denote by $V_\omega$ the subset of $V$ consisting of those triples $v = (x, y, z)$ for which $x \in N(\omega)\cdot \StW(\Phi, A)$.


\begin{dfn} \label{sigma-def}
  Define a function $\sigma(\omega) \colon V_\omega \to V_{-\omega}$ via the following formula:
  \begin{equation} \label{eq:sigma-def} \sigma(\omega)(x_1 \cdot x_2, y, z) \mapsto (\delta(\omega)(x_1)\cdot x_2, x_2^{-1} \cdot \chi_{\omega, X}(x_2 \cdot y), \widetilde{\chi}(\omega, X)(z)), \end{equation}
  where $x_1 \in N(\omega)$, $x_2 \in \StW(\Phi, A)$,  $y \in B$, $z \in G_M$.

  By~\cref{lem:winv-chiw} the factor $x_2^{-1} \cdot \chi_{\omega, X}(x_2)$ lies in $\StH(\Phi, A[X^{\pm 1}])$, so the second component of the above triple belongs to $B$. At this point, it is not immediately clear why the above definition does not depend on the choice of decomposition $x = x_1 \cdot x_2$.
\end{dfn}


Set $\Delta = \Delta_k$ (the symmetric subset of $\Phi$ consisting of $\alpha$ with $m_k(\alpha)=0$). Recall that the coset set $W(\Delta) \setminus W(\Phi)$ is in one-to-one correspondence with $\Lambda$ (the set of minuscule weights of the representation $\pi$ with highest weight $\varpi_k^\vee$). For each minuscule weight $\lambda \in \Lambda = W(\Phi)\cdot \varpi_k$ we choose a representative $w_\lambda \in W(\Phi)$ a representative for the coset $W(\Delta) w_\lambda$.


\begin{rem} Each $w_\lambda$ can be chosen to be a product of at most $p$ reflections $w_\beta(1)$ for $\beta\in\Sigma_k$, where $p = 2$ for $\Phi = \rD_\ell, \rE_6$ or $p = 3$ for $\Phi = \rE_7$. \end{rem}

Denote by $w_{\lambda, u}$ an element of the form $\prod w_{\alpha_i}(u_i) \in W(\Phi, A)$ such that $\prod u_i = u$, $\alpha_i \in \Sigma_k$ and $\varpi_k + \sum \alpha_i = \lambda$.
{\bf In this sum all $\alpha_i$'s are different!}
If $\lambda = \varpi_k$ set $w_{\lambda, \varpi_k}(u) = h_\alpha(u)$ for some $\alpha \in \Sigma_k$.
%There is a map $\iota \colon W(\Phi) \to W(\Phi, A)$ given by $s_{\alpha_i} \mapsto w_{\alpha_i}(\pm 1)$ (this does not depend on the choice of the set $S = \{s_{\alpha_i}\}_{\alpha_i \in \Pi}$ of simple reflections of $W(\Phi)$, however, it is {\it not} a homomorphism of groups).


\begin{lemma} \label{lem:can-repr} One has \[N(\varpi_k^\vee) \cdot \StW(\Phi, A) = \bigsqcup\limits_{(u, \lambda) \in A^\times \times \Lambda} N(\varpi_k^\vee) \cdot w_{\lambda, u}. \]
\end{lemma}
\begin{proof}
 First, we construct bijections between the following coset sets:
 \begin{equation}\label{eq:repr} \StW(\Delta, A) \setminus \StW(\Phi, A) \cong W(\Delta, A) \setminus W(\Phi, A) \xrightarrow{\cong} A^\times \times \Lambda.\end{equation}
 The first bijection exists since $A$ is local and $\K_2(\Phi, A) \cong \K_2(\Delta, A)$.

 Notice that for $w \in W(\Phi, A)$ there exists a unique weight $\lambda \in \Lambda$ such that the coordinate $(w \cdot v^+)_{\lambda, \varpi_k}$ is nonzero (here $v^+$ denotes the highest-weight vector). Denote this coordinate by $u$. Thus, the second map can be given by $w \mapsto (u, \lambda)$. Conversely, we can send each pair $(u, \lambda)$ to a representative $w_{\lambda, u}$. It is easy to see that the resulting $N(\varpi_k^\vee)$ does not depend on this choice.


 It remains to notice that $N(\varpi_k) \supseteq \StW(\Delta, A)$ and that for each $g \in N(\varpi_k)$ the element $\pi(g(0))$ stabilizes the highest weight vector $v^+$.
\end{proof}


Notice that for $g \in \StW(\Delta, A)$ one has $\chi_{\omega, X}(g) = g$ therefore we obtain the following
\begin{cor}
 The right-hand side of~\eqref{eq:sigma-def} does not depend on the choice of decomposition $x = x_1 \cdot x_2$, so $\sigma(\omega)$ is defined unambigously.
\end{cor}


\begin{comment}
We will also need to compute $x^{-1} \cdot \chi_{\omega, X}(x)$ for the representative $x = h_{\alpha_k}(u)\iota(w_\lambda)$. For simplicity, we may assume $w_\lambda = w_\beta(1)$, $\beta \in \Sigma_k$.
\begin{multline} x^{-1} \cdot \chi_{\omega, X}(x) = \{ X, u\} \cdot \iota(w_\lambda)^{-1} \chi_{\omega, X}(w_\lambda) = \\ = \{X, u\} \cdot w_\beta(1)^{-1} w_\beta(X)
\end{multline}
\end{comment}


Our next goal is to show that the function $\sigma(\omega)$ gives rise to a well-defined function
 \[\sigma(\omega)\colon V/\sim \to V/\sim.\]
The first ingredient is the following
\begin{lemma}
 For every $v \in V$ there exists $(a, b, 1) \in W$ such that $(a, b, 1) \star v \in V_\omega$.
\end{lemma}
\begin{proof}
 Choose some system of positive roots $\Phi^{+'}$ in such a way that $(\alpha, \omega) \geq 0$ for all $\alpha \in \Phi^{+'}$, i.\,e. $\UU(\Phi^{+'}, A) \subseteq N(\omega)$.
 From~\eqref{eq:bruhat} we obtain that \[G^+ = \UU(\Phi^{+'}, A)\cdot \St(\Phi, A[X], XA[X]) \cdot \StW(\Phi,A)\cdot \overline{\St}(\Phi, A, M) \cdot\UU(\Phi^+, A).\]
 The first two factors in the above decomposition are contained in $N(\omega)$, so the assertion follows from the definition of $\star$.
\end{proof}


\begin{lemma} \label{h-computation} Set $ x = w_{\lambda, u} = w_{\alpha'}(u) \cdot [w_{\alpha''}(1) \cdot w_{\alpha'''}(1)]$ for some $\alpha', \alpha'', \alpha''' \in \Sigma_k$ (or $x = h_{\alpha'}(u)$ if $\lambda = \varpi_k$). We claim that:
 \begin{equation*} h_{\alpha'}(1+m)^{x^{-1} \cdot \chi_{\varpi_k, X}(x)} = \left\{\begin{array}{ll} h_{\alpha'}(1+m) & \text{if $\lambda = \varpi_k$,}\\ \{X^2, 1+m\} \cdot h_{\alpha'}(1+m) & \text{otherwise.}\end{array}\right. \end{equation*}
\end{lemma}
\begin{proof}
In the case $\lambda = \varpi_k$ it is clear that $x^{-1} \cdot \chi_{\varpi_k, X}(x) \in \K_2(\Phi, A[X^{\pm 1}])$, so the assertion of the lemma is clear in this case.


Now suppose that $\lambda \neq \varpi_k$. We claim that $x^{-1} \cdot \widetilde{\chi}_{\omega, X}(x) \equiv h_{\alpha'}^{-1}(X)$ modulo $\K_2(\Phi, A[X^{\pm 1}])$. It is clear that lemma's assertion would follow from this.


We already know from~\cref{lem:winv-chiw} that
\[x_2^{-1} \cdot \widetilde{\chi}_{\omega, X}(x_2) \equiv w_{\alpha'}(u)^{-1} \cdot \widetilde{\chi}_{\omega, X}(w_{\alpha'}(u)) \equiv h_{\alpha'}^{-1}(X). \]
Now suppose that $x = w_{\alpha'}(u)\cdot w_{\alpha''}(1)$. Using the already established case we obtain that
\begin{multline*} x^{-1} \cdot \chi_{\omega, X}(x) \equiv w_{\alpha''}^{-1}(1) \cdot h_{\alpha'}^{-1}(X) \cdot \chi_{\omega, X}(w_{\alpha''}(1)) \equiv \\
\equiv h_{\alpha'}^{-1}(X) \cdot w_{\alpha''}^{-1}(X) \cdot \chi_{\omega, X}(w_{\alpha''}(1)) \equiv h_\alpha^{-1}(X). \end{multline*}
Here we use the fact that $\alpha' \neq \alpha''$.
Similar computation also applies in the case when $w_{\lambda, u}$ is a product of three Weyl elements.
\end{proof}


\begin{lemma}
 For every $w \in W$, $v \in V_\omega$ such that $v' = w \star v \in V_\omega$ there exists $w' \in W$ such that $\sigma(\omega)(w \star v) = w' \star \sigma(\omega)(v)$.
\end{lemma}
\begin{proof}
 It suffices to consider the case $\omega = \varpi_k^\vee$. Suppose that $v' = (x_1' x_2', y', z') = (a, b, 1) \star v$, where $v = (x_1 x_2, y, z)$. We have that
 \begin{equation}\label{eq:x-xprime} x_1' x_2' = x_1 x_2 \cdot \pi(b) \cdot a  \text{ for some }x_1, x_1' \in N(\omega),\ x_2, x_2' \in \StW(\Phi, A) \end{equation}
 and some $a \in \UU(\Phi^+, A[X]),\ b \in \St(\Phi, A[X], M[X])$. Thanks to~\cref{lem:can-repr} we may assume, without loss of generality, that $x_2 = w_{\lambda, u}$, $x_2' = w_{\lambda', u'}$
for some $u, u' \in A^\times$, $\lambda, \lambda' \in \Lambda$.


Evaluating both sides of~\eqref{eq:x-xprime} at $X=0$ and projecting them to $\St(\Phi, k)$ we obtain the equality $\overline{x_1'}(0) \cdot \overline{x_2'} = \overline{x_1}(0) \cdot \overline{x_2}\cdot \overline{a}(0).$
Since $x_1(0)$, $x_1'(0)$ and $a$ stabilize the highest weight vector we obtain that $\lambda = \lambda'$ and that $u - u' \in M$ (cf. the proof of~\cref{lem:can-repr}).
Again, without loss of generality we may assume $w_{\lambda, u} = w_{\alpha'}(u) \cdot [ w_{\alpha''}(1) \cdot w_{\alpha'''}(1)]$. Set $m = 1 - u/u'$, clearly $x_2 = c \cdot x_2' \cdot h_{\alpha'}(1 + m)$ for some $c \in \K_2(\Phi, A)$.


Set $\epsilon = 1$ if $\lambda\neq \varpi_k$, otherwise set $\epsilon = -1$.
From~\eqref{eq:chi-h},~\cref{lem:delta-k2-trivial} and~\cref{h-computation} we obtain that
\begin{equation}\label{eq:central-term} {x_2}^{-1} \cdot \chi_{\omega, X}(x_2) = \{1+m, X^\epsilon\} \cdot \bigl({x_2'}^{-1} \cdot \chi(\omega, x_2')\bigr), \end{equation}
while from~\eqref{eq:x-xprime} and \cref{delta-weyl} we get that
$\pi(b) \cdot a \cdot h_{\alpha'}(1 + m) \in N(\omega')$ for $\omega' = w_\lambda^{-1} \cdot \omega$. By~\cref{lem:q} we can find $q \in \UU(\Phi^+, M[X])$ such that $a q^{-1}$ and the image of $b' = q \cdot b^a \cdot h_{\alpha'}(1+m) \in \St(\Phi, A[X], M[X])$ under $\pi$ both belong to $N(\omega')$.


\begin{multline} \label{eq:computation1}
 \sigma(\omega)(x_1'x_2', y', z') =
 \bigl(\delta_\omega(x_1') \cdot x_2',\, x_2'^{-1}\cdot \chi_{\omega, X}(x_2' y'),\, \chi_{\omega, X}(z')\bigr) = \\
 = \bigl(\delta_\omega(x_1) \cdot \delta_\omega(x_2 \pi(b) a {x_2'}^{-1}) \cdot x_2',\, \{X^\epsilon, 1+m\} \cdot x_2^{-1}\cdot \chi_{\omega, X}(x_2 y'), \chi_{\omega, X}(z') \bigr) = \\
 = \bigl(\delta_\omega(x_1) \cdot x_2 \cdot \delta_{\omega'}(aq^{-1}) \cdot \delta_{\omega'}(\pi(b')) \cdot h^{-1}_{\alpha'}(1+m),\, \{X^\epsilon, 1+m\} \cdot x_2^{-1}\cdot \chi_{\omega, X}(x_2 y'), \widetilde{\chi}_{\omega, X}(z') \bigr) = \\
 = (1, 1, \widetilde{\chi}_{\omega', X}(b') \cdot h_{\alpha'}^{-1}(1+m)) \star \\ \star \bigl(\delta_\omega(x_1) \cdot x_2 \cdot \delta_{\omega'}(aq^{-1}),\, \{X^\epsilon, 1+m\} \cdot x_2^{-1}\cdot \chi_{\omega, X}(x_2 y'), \bigl(\widetilde{\chi}_{\omega', X}(b') h^{-1}_{\alpha'}(1+m)\bigr)^{x_2^{-1} \cdot \chi_{\omega, X}(x_2 y')} \widetilde{\chi}_{\omega, X}(z') \bigr).
\end{multline}


Now let us compute the third coordinate:
\begin{multline} \bigl(\widetilde{\chi}_{\omega', X}(b') \cdot h^{-1}_{\alpha'}(1+m)\bigr)^{x_2^{-1} \cdot \chi_{\omega, X}(x_2 y')} \widetilde{\chi}_{\omega, X}(z') = \\ =
\bigl(\widetilde{\chi}_{\omega', X}(q \cdot b^a \cdot h_{\alpha'}(1+m)) \cdot h^{-1}_{\alpha'}(1+m)\bigr)^{x_2^{-1} \cdot \chi_{\omega, X}(x_2 y')} \widetilde{\chi}_{\omega, X}(b^{-y}z) = \text{by~\cref{h-computation}}  \\ = \bigl(\widetilde{\chi}_{\omega, X}((q \cdot b^a \cdot h_{\alpha'}(1+m))^{x_2^{-1}}) \bigr)^{\chi_{\omega, X}(x_2 y')} \cdot h_{\alpha'}(1+m)^{-\chi_{\omega, X}(y')} \cdot \{1 + m, X^{\epsilon + 1} \} \cdot \widetilde{\chi}_{\omega, X}(b^{-y}z) = \\ = \widetilde{\chi}_{\omega, X}\bigl((q \cdot b^a \cdot h_{\alpha'}(1+m))^{y'}\bigr) \cdot \widetilde{\chi}_{\omega, X}\bigl(h_{\alpha'}(1+m)\bigr)^{-\chi_{\omega, X}(y')} \cdot \{1 + m, X^\epsilon \} \cdot \widetilde{\chi}_{\omega, X}(b^{-y}z) = \\ = \{ 1+m, X^\epsilon \} \cdot \widetilde{\chi}_{\omega, X}(q^{y'} \cdot z).
\end{multline}


Now recalling that $y' = a ^{-1} y, z' = b^{-y} z$ we can continue~\eqref{eq:computation1} as follows:
\begin{multline*}
 \bigl(\delta_\omega(x_1) \cdot x_2 \cdot \delta_{\omega'}(aq^{-1}),\, x_2^{-1}\cdot \chi_{\omega, X}(x_2 y'), \widetilde{\chi}_{\omega, X}(q^{y'} z) \bigr) = \\ = (\delta_{\omega'}(qa^{-1}), 1, \chi_{\omega, X}(q^{y'})) \star \bigl(\delta_\omega(x_1) \cdot x_2,\, \cdot \chi_{\omega', X}(aq^{-1}) \cdot x_2^{-1}\cdot \chi_{\omega, X}(x_2 q a^{-1} \cdot y ), \widetilde{\chi}_{\omega, X}(z) \bigr) = \\ = (\ldots) \star (\delta_\omega(x_1) \cdot x_2,\, x_2^{-1} \chi_{\omega, X}(x_2y), \widetilde{\chi}_{\omega, X}(z)) \end{multline*} \end{proof}


 For $w\in W(\Phi)$ denote by $\Stab_{w}$ the algebraic subgroup of $\G_{sc}(\Phi, -)$ consisting of elements stabilizing the vector $\iota(w) \cdot v^+$. It is clear that the resulting subgroup does not depend on the exact choice of $\iota$. Recall that the projection $\varphi \colon \St(\Phi, R) \to \G_{sc}(\Phi, R)$ is always injective on unipotent subgroups. Moreover, it is clear that $N(w \cdot \varpi_k)(0) = \varphi^{-1}(\Stab_w(A[X]))$.

\begin{lemma} \label{lem:q}
Let $R$ be a commutative ring, $I$ be an ideal of $R$.
Suppose that $a \in \UU(\Phi^+, R)$ is such that its image $\varphi(\overline{a})$ lies in $\Stab_{w}(R/I)$ for some $w \in W(\Phi)$.
Then there exists $q \in \UU(\Phi^+, I)$ such that $\varphi(aq)$ lies in $\Stab_{w}(R)$.
\end{lemma}
\begin{proof}
Set $b = a^{\iota(w)}$.
Notice that $(b \cdot v_+)_{\varpi_k} = 1$, therefore by the Chevalley--Matsumoto decomposition we can write $b = b_1 \cdot b_2$ for some $b_1$ such that $\varphi(b_1) \in \Stab_1(R)$ and $b_2 \in \UU(\Sigma_k^-, R)$.
It is also clear from our assumptions that $b_2$, in fact, belongs to $\UU(\Sigma_k^-, I)$.
Set $a_i = {}^{\iota(w)}b_i$.
It is clear that $\varphi(a_1) \in \Stab_w(R)$, $\varphi(a_2) \in \UU(\Phi^+ \cap w(\Sigma_k^-), I)$ and $a = a_1 \cdot a_2$ as claimed.
\end{proof}
